# Big-Data-Management
Spring 2017
Big data is sometimes defined as data that are too big to fit onto the analyst’s computer. With storage and networking getting significant cheaper and faster, big data sets could easily reach the hands of data enthusiasts with just a few mouse clicks. These enthusiasts could be policy makers, government employees or managers, who would like to draw insights and (business) value from big data. Thus, it is crucial for big data to be made available to the non-expert users in such a way that they can process the data without the need of a supercomputing expert. One such approach is to build big data programming frameworks that can deal with big data in as close a paradigm as the way it deals with “small data.” Also such a framework should be as simple as possible, even if not as efficient as custom-designed parallel solutions. Users should expect that if their code works within these frameworks for small data, it will also work for big data.

The course aims to provide a broad understanding of big data and current technologies in managing and processing them with a focus on the urban environment. General topics include big data ecosystems, parallel and streaming programming model, MapReduce, Hadoop, Spark, Pig, and NoSQL solutions. Hands-on labs and exercises will be offered throughout to bolster the knowledge learned in each module.

## Course Outcomes

* Understand the big data ecosystem including its data life cycle
* Gain experience in identifying big urban data challenges and develop analytical solutions for them
* Understand the big data programming paradigm: streaming, parallel computing and MapReduce
* Gain knowledge in implementing analytical tools to analyze big data with Apache Spark & Hadoop
