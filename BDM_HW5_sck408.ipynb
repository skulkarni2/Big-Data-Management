{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x1029a8c18>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd = sc.textFile('/usr/local/Cellar/apache-spark/2.1.0/README.md')\n",
    "testrdd = sc.parallelize([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testrdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# Apache Spark',\n",
       " '',\n",
       " 'Spark is a fast and general cluster computing system for Big Data. It provides',\n",
       " 'high-level APIs in Scala, Java, Python, and R, and an optimized engine that',\n",
       " 'supports general computation graphs for data analysis. It also supports a',\n",
       " 'rich set of higher-level tools including Spark SQL for SQL and DataFrames,',\n",
       " 'MLlib for machine learning, GraphX for graph processing,',\n",
       " 'and Spark Streaming for stream processing.',\n",
       " '',\n",
       " '<http://spark.apache.org/>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(10)  ## take returns the text.. top returns the top work counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guide,', 1), ('development', 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc = rdd.flatMap(lambda line: line.split()) \\\n",
    "                .map(lambda x: (x.lower(), 1)) \\\n",
    "                .groupByKey() \\\n",
    "                .mapValues(lambda values: sum(values))\n",
    "\n",
    "wc.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guide,', 1), ('development', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc = rdd.flatMap(lambda line: line.split()) \\\n",
    "                .map(lambda x: (x.lower(),1)) \\\n",
    "                .reduceByKey(lambda x,y: x+y)\n",
    "wc.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : Compute the average SAT Math score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sat_FN = 'SAT_Results.csv'\n",
    "HSD_FN = 'DOE_High_School_Directory_2014-2015.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read csv format in spark as a dataframe \n",
    "# Below is a way to read CSV file from within Spark directly into a \n",
    "# Spark's DataFrame, which we will not be covering yet. Just putting\n",
    "# it here so that we have a reference for now. Note that, the \n",
    "# 'parserLib' option is important for reading multi-line fields of CSV.\n",
    "df = spark.read \\\n",
    "            .format(\"com.databricks.spark.csv\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"inferSchema\", \"true\") \\\n",
    "            .option(\"parserLib\", \"UNIVOCITY\") \\\n",
    "            .load(HSD_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We read the SAT score to our RDD. Note that the use_unicode can be\n",
    "# changed accordingly to your data file to handle Unicode. If you cannot\n",
    "# parse your data due to an 'utf8' or 'ascii' decoding issue, it might\n",
    "# be a good thing to try flipping the use_unicode parameter here.\n",
    "\n",
    "sat = sc.textFile(Sat_FN, use_unicode=True).cache()\n",
    "\n",
    "# This line for us to list the column index and column names to see\n",
    "# which column we need to use for our task. In this case, we're\n",
    "# interested in the number of test takers (#2) and the math score (#4).\n",
    "#list(enumerate(sat.first().split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('01M292', (11716, 29)),\n",
       " ('01M448', (38493, 91)),\n",
       " ('01M450', (28140, 70)),\n",
       " ('01M458', (2807, 7)),\n",
       " ('01M509', (19052, 44))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractScores(partId, records):  #parts: list of records, partid: first element of first block\n",
    "    #skipping tthe first line\n",
    "    if partId == 0:  \n",
    "        records.__next__()\n",
    "    import csv\n",
    "    reader = csv.reader(records)\n",
    "    for row in reader:\n",
    "        if row[2]!='s': # to filter our bad-quality data\n",
    "            (dbn,takers,score) = (row[0], int(row[2]), int(row[4]))\n",
    "            yield (dbn, (score*takers, takers))\n",
    "\n",
    "## the large school ID and the test takes and the scores. \n",
    "satScores = sat.mapPartitionsWithIndex(extractScores)\n",
    "satScores.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBN,SCHOOL NAME,Num of SAT Test Takers,SAT Critical Reading Avg. Score,SAT Math Avg. Score,SAT Writing Avg. Score\n"
     ]
    }
   ],
   "source": [
    "noHeaderRDD = sat.filter(lambda x: not x.startswith('DBN,SCHOOL'))\n",
    "print (sat.first())\n",
    "#print (noHeaderRDD.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'dbn'),\n",
       " (1, 'school_name'),\n",
       " (2, 'boro'),\n",
       " (3, 'building_code'),\n",
       " (4, 'phone_number'),\n",
       " (5, 'fax_number'),\n",
       " (6, 'grade_span_min'),\n",
       " (7, 'grade_span_max'),\n",
       " (8, 'expgrade_span_min'),\n",
       " (9, 'expgrade_span_max'),\n",
       " (10, 'bus'),\n",
       " (11, 'subway'),\n",
       " (12, 'primary_address_line_1'),\n",
       " (13, 'city'),\n",
       " (14, 'state_code'),\n",
       " (15, 'zip'),\n",
       " (16, 'website'),\n",
       " (17, 'total_students'),\n",
       " (18, 'campus_name'),\n",
       " (19, 'school_type'),\n",
       " (20, 'overview_paragraph'),\n",
       " (21, 'program_highlights'),\n",
       " (22, 'language_classes'),\n",
       " (23, 'advancedplacement_courses'),\n",
       " (24, 'online_ap_courses'),\n",
       " (25, 'online_language_courses'),\n",
       " (26, 'extracurricular_activities'),\n",
       " (27, 'psal_sports_boys'),\n",
       " (28, 'psal_sports_girls'),\n",
       " (29, 'psal_sports_coed'),\n",
       " (30, 'school_sports'),\n",
       " (31, 'partner_cbo'),\n",
       " (32, 'partner_hospital'),\n",
       " (33, 'partner_highered'),\n",
       " (34, 'partner_cultural'),\n",
       " (35, 'partner_nonprofit'),\n",
       " (36, 'partner_corporate'),\n",
       " (37, 'partner_financial'),\n",
       " (38, 'partner_other'),\n",
       " (39, 'addtl_info1'),\n",
       " (40, 'addtl_info2'),\n",
       " (41, 'start_time'),\n",
       " (42, 'end_time'),\n",
       " (43, 'se_services'),\n",
       " (44, 'ell_programs'),\n",
       " (45, 'school_accessibility_description'),\n",
       " (46, 'number_programs'),\n",
       " (47, 'priority01'),\n",
       " (48, 'priority02'),\n",
       " (49, 'priority03'),\n",
       " (50, 'priority04'),\n",
       " (51, 'priority05'),\n",
       " (52, 'priority06'),\n",
       " (53, 'priority07'),\n",
       " (54, 'priority08'),\n",
       " (55, 'priority09'),\n",
       " (56, 'priority10'),\n",
       " (57, 'Location 1')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schools = sc.textFile(HSD_FN, use_unicode=True).cache()\n",
    "list(enumerate(schools.first().split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('09X327', 'Bronx'),\n",
       " ('28Q680', 'Queens'),\n",
       " ('14K474', 'Brooklyn'),\n",
       " ('02M420', 'Manhattan'),\n",
       " ('12X271', 'Bronx'),\n",
       " ('02M520', 'Manhattan'),\n",
       " ('24Q600', 'Queens'),\n",
       " ('10X368', 'Bronx'),\n",
       " ('06M348', 'Manhattan'),\n",
       " ('13K419', 'Brooklyn')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractSchools(partID, list_of_records):\n",
    "    '''\n",
    "    This function extracts the school ID for large schools and the boro name for each school\n",
    "    '''\n",
    "    if partID==0:\n",
    "        list_of_records.__next__()    ## skipping the  first line\n",
    "    import csv\n",
    "    reader = csv.reader(list_of_records)    \n",
    "    for row in reader:\n",
    "        if len(row)==58 and row[17].isdigit():\n",
    "            (dbn,boro, total_students) = (row[0], row[2], int(row[17]))\n",
    "            if total_students>500:\n",
    "                yield (dbn, boro)\n",
    "        \n",
    "        \n",
    "largeSchools = schools.mapPartitionsWithIndex(extractSchools)\n",
    "largeSchools.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = largeSchools.join(satScores).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Brooklyn', (22066, 59)),\n",
       " ('Manhattan', (150864, 336)),\n",
       " ('Queens', (66420, 135))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = largeSchools.join(satScores).values() \\\n",
    "    .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])) \\\n",
    "    .mapValues(lambda x: int(x[0]/x[1])) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Staten Island', 477),\n",
       " ('Bronx', 470),\n",
       " ('Brooklyn', 487),\n",
       " ('Manhattan', 514),\n",
       " ('Queens', 474)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 2: Math scores across every bus line or subway line serving the schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('17K548', 'B41, B43, B44-SBS, B45, B48, B49, B69'),\n",
       " ('09X543', 'Bx13, Bx15, Bx17, Bx21, Bx35, Bx4, Bx41, Bx4A, Bx6'),\n",
       " ('09X327', 'Bx1, Bx11, Bx13, Bx18, Bx2, Bx3, Bx32, Bx35, Bx36'),\n",
       " ('28Q680', 'Q25, Q46, Q65'),\n",
       " ('08X348', 'Bx21, Bx24, Bx31, Bx4, Bx40, Bx42, Bx4A, Bx8')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractSchools_busline(partId, list_of_records):\n",
    "    '''\n",
    "    This function extracts the large school Ids and the bus line numbers\n",
    "    '''\n",
    "    if partId==0:\n",
    "        # Skip the header\n",
    "        list_of_records.__next__()    ## for python 2 compatibility use 'next()' instead of '__next__()'  \n",
    "    import csv\n",
    "    reader = csv.reader(list_of_records)\n",
    "    \n",
    "    for row in reader:\n",
    "        if len(row)==58 and row[17].isdigit():\n",
    "            (dbn, bus, tot_students) = (row[0], row[10], int(row[17]))\n",
    "            if tot_students > 1:\n",
    "                yield(dbn, bus)\n",
    "\n",
    "largeSchools = schools.mapPartitionsWithIndex(extractSchools_busline)\n",
    "largeSchools.take(5)   ## the school id and the bus lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bx12, Bx12-SBS, Bx26, Bx39, Bx8', (23460, 60)),\n",
       " ('Bx1, Bx10, Bx7, Bx9, M100', (21330, 54))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Joining satscores to school dataset which has the bus line information. \n",
    "scores_buslines = largeSchools.join(satScores).values()\n",
    "scores_buslines.take(2)     ## buslines and the sat scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pairing(values):\n",
    "    '''\n",
    "    This function creates a pair of keys and values associated with the key. \n",
    "    '''\n",
    "    count = 0 \n",
    "    list_values = []\n",
    "    for value in values:\n",
    "        keys = value[0]\n",
    "        score = value[1]\n",
    "        for key in keys:\n",
    "            list_values.append((key, score))\n",
    "    yield list_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bus_avg_score = scores_buslines.map(lambda x: (x[0].split(','), x[1]))\\\n",
    "                .mapPartitions(pairing)\\\n",
    "                .flatMap(lambda x: x)\\\n",
    "                .map(lambda x: (x[0].strip(), x[1]))\\\n",
    "                .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1]))\\\n",
    "                .mapValues(lambda x: int(x[0]/x[1]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B1', 461),\n",
       " ('B100', 475),\n",
       " ('B103', 531),\n",
       " ('B11', 503),\n",
       " ('B12', 390),\n",
       " ('B13', 397),\n",
       " ('B14', 390),\n",
       " ('B15', 382),\n",
       " ('B16', 448),\n",
       " ('B17', 385),\n",
       " ('B2', 475),\n",
       " ('B20', 372),\n",
       " ('B24', 432),\n",
       " ('B25', 541),\n",
       " ('B26', 389),\n",
       " ('B3', 382),\n",
       " ('B31', 475),\n",
       " ('B32', 409),\n",
       " ('B35', 390),\n",
       " ('B36', 432),\n",
       " ('B38', 520),\n",
       " ('B39', 438),\n",
       " ('B4', 466),\n",
       " ('B41', 520),\n",
       " ('B42', 384),\n",
       " ('B43', 411),\n",
       " ('B44', 465),\n",
       " ('B44-SBS', 465),\n",
       " ('B45', 534),\n",
       " ('B46', 390),\n",
       " ('B47', 374),\n",
       " ('B48', 412),\n",
       " ('B49', 471),\n",
       " ('B52', 560),\n",
       " ('B54', 543),\n",
       " ('B57', 405),\n",
       " ('B6', 467),\n",
       " ('B60', 398),\n",
       " ('B61', 400),\n",
       " ('B62', 513),\n",
       " ('B63', 557),\n",
       " ('B64', 454),\n",
       " ('B65', 538),\n",
       " ('B67', 420),\n",
       " ('B68', 465),\n",
       " ('B69', 548),\n",
       " ('B7', 378),\n",
       " ('B70', 476),\n",
       " ('B8', 485),\n",
       " ('B82', 440),\n",
       " ('B83', 376),\n",
       " ('B84', 432),\n",
       " ('B9', 489),\n",
       " ('Bx1', 464),\n",
       " ('Bx10', 534),\n",
       " ('Bx11', 389),\n",
       " ('Bx12', 405),\n",
       " ('Bx12-SBS', 405),\n",
       " ('Bx13', 398),\n",
       " ('Bx15', 393),\n",
       " ('Bx17', 389),\n",
       " ('Bx18', 382),\n",
       " ('Bx19', 413),\n",
       " ('Bx2', 470),\n",
       " ('Bx20', 455),\n",
       " ('Bx21', 398),\n",
       " ('Bx22', 525),\n",
       " ('Bx23', 392),\n",
       " ('Bx24', 430),\n",
       " ('Bx26', 533),\n",
       " ('Bx27', 371),\n",
       " ('Bx28', 489),\n",
       " ('Bx29', 392),\n",
       " ('Bx3', 571),\n",
       " ('Bx30', 401),\n",
       " ('Bx31', 417),\n",
       " ('Bx32', 397),\n",
       " ('Bx33', 426),\n",
       " ('Bx34', 416),\n",
       " ('Bx35', 389),\n",
       " ('Bx36', 372),\n",
       " ('Bx38', 378),\n",
       " ('Bx39', 395),\n",
       " ('Bx4', 391),\n",
       " ('Bx40', 400),\n",
       " ('Bx41', 388),\n",
       " ('Bx41-SBS', 389),\n",
       " ('Bx42', 400),\n",
       " ('Bx46', 376),\n",
       " ('Bx4A', 391),\n",
       " ('Bx5', 382),\n",
       " ('Bx6', 396),\n",
       " ('Bx7', 402),\n",
       " ('Bx8', 409),\n",
       " ('Bx9', 389),\n",
       " ('M1', 413),\n",
       " ('M10', 495),\n",
       " ('M100', 427),\n",
       " ('M101', 453),\n",
       " ('M102', 455),\n",
       " ('M103', 441),\n",
       " ('M104', 477),\n",
       " ('M106', 470),\n",
       " ('M11', 477),\n",
       " ('M116', 467),\n",
       " ('M14A', 475),\n",
       " ('M14D', 468),\n",
       " ('M15', 459),\n",
       " ('M15-SBS', 452),\n",
       " ('M2', 449),\n",
       " ('M20', 540),\n",
       " ('M21', 485),\n",
       " ('M22', 574),\n",
       " ('M23', 462),\n",
       " ('M3', 432),\n",
       " ('M31', 490),\n",
       " ('M34-SBS', 417),\n",
       " ('M34A-SBS', 437),\n",
       " ('M35', 496),\n",
       " ('M4', 442),\n",
       " ('M42', 410),\n",
       " ('M5', 520),\n",
       " ('M50', 438),\n",
       " ('M57', 485),\n",
       " ('M60', 357),\n",
       " ('M66', 518),\n",
       " ('M7', 483),\n",
       " ('M72', 523),\n",
       " ('M79', 594),\n",
       " ('M8', 467),\n",
       " ('M86', 538),\n",
       " ('M9', 539),\n",
       " ('M96', 401),\n",
       " ('M98', 409),\n",
       " ('N/A', 423),\n",
       " ('Q1', 412),\n",
       " ('Q10', 404),\n",
       " ('Q100', 454),\n",
       " ('Q101', 464),\n",
       " ('Q102', 474),\n",
       " ('Q103', 443),\n",
       " ('Q104', 452),\n",
       " ('Q11', 434),\n",
       " ('Q110', 462),\n",
       " ('Q111', 446),\n",
       " ('Q112', 441),\n",
       " ('Q113', 438),\n",
       " ('Q12', 438),\n",
       " ('Q13', 492),\n",
       " ('Q15', 438),\n",
       " ('Q15A', 438),\n",
       " ('Q16', 445),\n",
       " ('Q17', 495),\n",
       " ('Q18', 434),\n",
       " ('Q2', 419),\n",
       " ('Q20A', 505),\n",
       " ('Q20B', 481),\n",
       " ('Q22', 435),\n",
       " ('Q23', 482),\n",
       " ('Q24', 434),\n",
       " ('Q25', 473),\n",
       " ('Q26', 438),\n",
       " ('Q27', 481),\n",
       " ('Q28', 492),\n",
       " ('Q29', 423),\n",
       " ('Q3', 456),\n",
       " ('Q30', 507),\n",
       " ('Q31', 504),\n",
       " ('Q32', 466),\n",
       " ('Q34', 441),\n",
       " ('Q35', 519),\n",
       " ('Q36', 466),\n",
       " ('Q37', 422),\n",
       " ('Q38', 456),\n",
       " ('Q39', 466),\n",
       " ('Q4', 479),\n",
       " ('Q40', 417),\n",
       " ('Q41', 440),\n",
       " ('Q42', 582),\n",
       " ('Q43', 432),\n",
       " ('Q44', 354),\n",
       " ('Q46', 451),\n",
       " ('Q48', 441),\n",
       " ('Q5', 456),\n",
       " ('Q50', 392),\n",
       " ('Q53', 437),\n",
       " ('Q54', 408),\n",
       " ('Q55', 394),\n",
       " ('Q56', 434),\n",
       " ('Q58', 410),\n",
       " ('Q59', 418),\n",
       " ('Q6', 446),\n",
       " ('Q60', 479),\n",
       " ('Q64', 529),\n",
       " ('Q65', 464),\n",
       " ('Q66', 461),\n",
       " ('Q67', 466),\n",
       " ('Q69', 444),\n",
       " ('Q7', 407),\n",
       " ('Q72', 423),\n",
       " ('Q76', 488),\n",
       " ('Q77', 413),\n",
       " ('Q8', 443),\n",
       " ('Q83', 449),\n",
       " ('Q84', 507),\n",
       " ('Q85', 485),\n",
       " ('Q88', 508),\n",
       " ('Q9', 462),\n",
       " ('S1115', 612),\n",
       " ('S40', 434),\n",
       " ('S42', 432),\n",
       " ('S44', 435),\n",
       " ('S46', 434),\n",
       " ('S48', 432),\n",
       " ('S51', 422),\n",
       " ('S52', 432),\n",
       " ('S53', 452),\n",
       " ('S54', 474),\n",
       " ('S55', 486),\n",
       " ('S56', 476),\n",
       " ('S57', 490),\n",
       " ('S59', 473),\n",
       " ('S61', 451),\n",
       " ('S62', 432),\n",
       " ('S66', 442),\n",
       " ('S74', 486),\n",
       " ('S76', 486),\n",
       " ('S78', 486),\n",
       " ('S79-SBS', 505),\n",
       " ('S89', 438)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bus_avg_score.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('17K548', '2, 3, 4, 5, F, S to Botanic Garden ; B, Q to Prospect Park'),\n",
       " ('09X543', '2, 5 to Intervale Ave')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractSchools_subwayline(partId, list_of_records):\n",
    "    '''\n",
    "    The function extracts the large school Ids and the subway lines\n",
    "    '''\n",
    "    if partId==0:\n",
    "        # Skip first header line\n",
    "        list_of_records.__next__()    ## for python 2 compatibility use 'next()' instead of '__next__()' \n",
    "    import csv\n",
    "    reader = csv.reader(list_of_records)\n",
    "    \n",
    "    for row in reader:\n",
    "        if len(row)==58 and row[17].isdigit():\n",
    "            (dbn, subway, tot_students) = (row[0], row[11], int(row[17]))\n",
    "            if tot_students > 1:\n",
    "                if subway == 'N/A':\n",
    "                    continue\n",
    "                yield(dbn, subway)\n",
    "\n",
    "largeSchools = schools.mapPartitionsWithIndex(extractSchools_subwayline)\n",
    "largeSchools.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2, 5 to Pelham Parkway', (23460, 60)),\n",
       " ('2, 5, B, Q to Church Ave', (22066, 59))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Joining satscores to school dataset which has the subway line information\n",
    "scores = largeSchools.join(satScores).values()\n",
    "scores.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subway_score = scores.map(lambda x: (x[0].split(' ; '), x[1]))\\\n",
    "                .mapPartitions(pairing)\\\n",
    "                .flatMap(lambda x: x)\\\n",
    "                .map(lambda x: (x[0].split(' to')[0], x[1]))\\\n",
    "                .map(lambda x: (x[0].split(','), x[1]))\\\n",
    "                .mapPartitions(pairing).flatMap(lambda x: x).map(lambda x: (x[0].strip(), x[1]))\\\n",
    "                .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1]))\\\n",
    "                .mapValues(lambda x: int(x[0]/x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 499),\n",
       " ('2', 488),\n",
       " ('3', 513),\n",
       " ('4', 495),\n",
       " ('5', 461),\n",
       " ('6', 432),\n",
       " ('7', 457),\n",
       " ('A', 510),\n",
       " ('B', 491),\n",
       " ('C', 510),\n",
       " ('D', 502),\n",
       " ('E', 501),\n",
       " ('F', 445),\n",
       " ('G', 503),\n",
       " ('J', 439),\n",
       " ('L', 426),\n",
       " ('M', 454),\n",
       " ('N', 493),\n",
       " ('Q', 482),\n",
       " ('R', 508),\n",
       " ('S', 427),\n",
       " ('SIR', 498),\n",
       " ('Z', 438)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(subway_score.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
